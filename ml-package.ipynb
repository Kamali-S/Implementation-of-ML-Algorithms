{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"752ff97ee9703573cfe8409ff4881f792455ef57"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cac7ae368adb7ea2a67c1610e7f8252b46376a88"},"cell_type":"code","source":"path = \"../input/train/train/\"\ndataframe = np.array([np.nan]*40000)\ndataframe_labels = np.array([np.nan])\ndataframe = dataframe.reshape(1,40000)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":true},"cell_type":"code","source":"import cv2\nimport copy\n# Resizing all the images into 200*200\ndim = (200, 200)\ncount = 0\nfor files in os.listdir(\"../input/train/train\"):\n    if(count < 2000):\n        im = cv2.imread(path+files, 0)\n        im = cv2.resize(im, dim)\n        im = im.reshape(1,im.shape[0]*im.shape[1])\n        dataframe = np.vstack((dataframe, im))\n        if(files.split(\".\")[0] == \"cat\"):\n            label = np.array([1])\n        else:\n            label = np.array([0])\n        dataframe_labels = np.vstack((dataframe_labels, label))\n        count = count + 1\n    else:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce669baefe81dcf46c4cbab15e72de86d88c7a57"},"cell_type":"code","source":"# removing the Nan values from dataframe \ndataframe = copy.copy(dataframe[1:,:])\ndataframe_labels = copy.copy(dataframe_labels[1:,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9712b7f2ff597031f682279c0643799d9c2e2c6"},"cell_type":"code","source":"# Splitting the dataframe into training and testing\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(dataframe, dataframe_labels, test_size=0.66, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9788974e2d935e628e5c69ac040a50dfcebd67ad"},"cell_type":"code","source":"# Normalising the values between 0 and 255\nX_train = X_train / 255\nX_test = X_test / 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a6d6216f640e01c1435e8e9329df389d19de97b8"},"cell_type":"code","source":"#reshape data to fit model\nX_train = X_train.reshape(-1,200,200,1)\nX_test = X_test.reshape(-1,200,200,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c76137d96212c2bbadc77ac57aa05ce87cd28f0f"},"cell_type":"code","source":"from keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89b9d6a2883889ebcee427c7c86943d34fd6c201"},"cell_type":"code","source":"#one-hot encoding the labels\nY_train = to_categorical(Y_train)\nY_test = to_categorical(Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb1e0b6318245d2171154c7a6c058c56fa42a8d7"},"cell_type":"code","source":"# Building CNN\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe6add640564d4f95155eef6ffabf61b53382ce5"},"cell_type":"code","source":"#create model\nmodel = Sequential()\n#add model layers\nmodel.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(200,200,1)))\nmodel.add(Conv2D(32, kernel_size=3, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(units=2,activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"56e7c69d6885c9da7f97487720352115eb234418"},"cell_type":"code","source":"#compile model using accuracy to measure model performance\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91f91c7d41f9c643722e3c36d699af0337c01241"},"cell_type":"code","source":"#train the model\nmodel.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbe53aa03ec4204592e75984c099bd4268b136c4"},"cell_type":"code","source":"model.predict(X_test[:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41504a00ba3b7b4841473d92ba85189cf510b558"},"cell_type":"code","source":"Y_test[:5] # PART 1 ENDS HERE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"64918c5ddb69601177d07c503e9ec4d7a3e046c8"},"cell_type":"code","source":"model.save(\"cats_dogs.py\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"34110d5481660044b23078a8315024d0976525ca"},"cell_type":"code","source":"fig=plt.figure()\nIMG_SIZE = 200\nfor num,data in enumerate(X_test[:12]):\n    y = fig.add_subplot(3,4,num+1)\n    data = data.reshape(1,IMG_SIZE,IMG_SIZE,1)\n    model_out = model.predict([data])[0]\n    \n    if np.argmax(model_out) == 1: \n        str_label='Dog'\n    else: \n        str_label='Cat'\n    data = data.reshape(200,200)\n    y.imshow(data,cmap='gray')\n    plt.title(str_label)\n    y.axes.get_xaxis().set_visible(False)\n    y.axes.get_yaxis().set_visible(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"29b2d8584e9866d363abe1472d2e96b122445074"},"cell_type":"code","source":"data = X_test[0].reshape(1,200,200,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ef46a3d815f6ae6b5af6cc88e8935ba599cc82ff"},"cell_type":"code","source":"prediction = model.predict([data])[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48b46408c18c523a2293cbf9071d4f5b8ddef22d"},"cell_type":"code","source":"image = cv2.imread(\"../input/train/train/dog.0.jpg\")\nimage1 = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nfrom scipy.signal import convolve2d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aff18b94a7c10442e6c82dd4368fcf42643895c8"},"cell_type":"code","source":"image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7f8222626a282364691a70c2ade0698112e568b"},"cell_type":"code","source":"kernel = np.ones((28,28), np.float32)/784\nconvolved = convolve2d(image1, kernel)\nfig = plt.figure(figsize=(15, 15))\nplt.subplot(121)\nplt.title('convolved_image')\nplt.axis('off')\nplt.imshow(image1, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"76a656c152d80f5de42bc71895dd1b1816da5318"},"cell_type":"code","source":"plt.imshow(image, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb3735d67f42a80d10f70bf1c96599df321c42bc"},"cell_type":"code","source":"# Edge detection\nedges = cv2.Canny(image,100,200)\nplt.subplot(121),plt.imshow(image,cmap = 'gray')\nplt.title('Original Image'), plt.xticks([]), plt.yticks([])\nplt.subplot(122),plt.imshow(edges,cmap = 'gray')\nplt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a67264b9647aa2da38616b00840ac6255d87006"},"cell_type":"code","source":"import cv2\nface_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n#face_cascade = cv2.CascadeClassifier('../home/haarcascade_frontalface_default.xml')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8000f71ddeefe13d5349f45686867886dca0fd77"},"cell_type":"code","source":"gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nfaces = face_cascade.detectMultiScale(gray, 1.3, 5)\n#face_cascade = cv2.CascadeClassifier('cascades/haarcascade_frontalface_default.xml')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"be799b01e65879cbecf3cedcffe7a749435562bc"},"cell_type":"code","source":"for (x, y, w, h) in faces:\n    cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n\nplt.imshow(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92d54db159781694eb0e54fb58bb1398f813bc90"},"cell_type":"code","source":"print(face_cascade.empty())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18cd419d492352afdfb4e23dfcbabaecf981d27e"},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"988aec80eba2e157cf2c021d273b56afca693c6e"},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9fd50d19eb1359994ce8df9d6f8e676c12e357ff"},"cell_type":"code","source":"datagen.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63716aa68cbe8cd678a0eb077f9c28d38ca8e31d"},"cell_type":"code","source":"model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32),steps_per_epoch=len(X_train) / 32, epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88ffbb9cec0fa6d2213e54a3528a4cadce0450d6"},"cell_type":"code","source":"model.predict(X_test, batch_size=32, verbose=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fb8084176577d6e4952f67ed3143cdcfa8f7031c"},"cell_type":"code","source":"import cv2\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"943156bc0dc66f408e660bde26ef0f3fed7ac4ff"},"cell_type":"code","source":"img = cv2.pyrDown(cv2.imread('../input/train/train/cat.0.jpg', cv2.IMREAD_UNCHANGED))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"285ffe5a7dd558643e0cc1bf230e861810aec86a"},"cell_type":"code","source":"ret, threshed_img = cv2.threshold(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY),\n                127, 255, cv2.THRESH_BINARY)\n\nimage, contours, hier = cv2.findContours(threshed_img, cv2.RETR_TREE,\n                cv2.CHAIN_APPROX_SIMPLE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ace33c31122cbd13b12283822b8cf9e7da4ed31d"},"cell_type":"code","source":"for c in contours:\n    x, y, w, h = cv2.boundingRect(c)\n    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57b16e46f2399e83b36269970f6f9f6b66070966"},"cell_type":"code","source":"rect = cv2.minAreaRect(c)\nbox = cv2.boxPoints(rect)\nbox = np.int0(box)\ncv2.drawContours(img, [box], 0, (0, 0, 255)).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0cc6514ff2e2ffa465077988b83d26af3fcdb01d"},"cell_type":"code","source":"(x, y), radius = cv2.minEnclosingCircle(c)\ncenter = (int(x), int(y))\nradius = int(radius)\nimg = cv2.circle(img, center, radius, (255, 0, 0), 2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"248f62f019567216631801ebaf816cf7d9aa342d"},"cell_type":"code","source":"print(len(contours))\ncv2.drawContours(img, contours, -1, (255, 255, 0), 1).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28d77c87969b0dd4cd47271a308ff45cdd610156"},"cell_type":"code","source":"import cv2\nfrom matplotlib import pyplot as plt\nplt.imshow(img)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}